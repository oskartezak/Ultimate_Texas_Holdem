{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feb0a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17156c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6225, 0.5000, 0.7311])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([.5, 0.0, 1.0])\n",
    "y = torch.sigmoid(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f023278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First round input shape: torch.Size([2245, 7])\n",
      "First round label shape: torch.Size([2245])\n",
      "Second round input shape: torch.Size([74989, 7])\n",
      "Second round label shape: torch.Size([74989])\n",
      "Third round input shape: torch.Size([748424, 7])\n",
      "Third round label shape: torch.Size([748424])\n",
      "Combined input shape: torch.Size([825658, 7])\n",
      "Combined label shape: torch.Size([825658])\n"
     ]
    }
   ],
   "source": [
    "def pad_to_length(tensor_list, max_len=7):\n",
    "    padded = pad_sequence(tensor_list, batch_first=True, padding_value=0)\n",
    "    if padded.size(1) < max_len:\n",
    "        pad_size = max_len - padded.size(1)\n",
    "        padded = F.pad(padded, (0, pad_size), value=0)\n",
    "    else:\n",
    "        padded = padded[:, :max_len]\n",
    "    return padded\n",
    "\n",
    "# Function to process and pad .npy dataset\n",
    "def process_round_data(npy_file, max_len=7):\n",
    "    data = np.load(npy_file)\n",
    "    x = data[:, :-1]\n",
    "    y = data[:, -1]\n",
    "    x_tensor_list = [torch.tensor(seq, dtype=torch.long) for seq in x]\n",
    "    x_padded = pad_to_length(x_tensor_list, max_len=max_len)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.float)\n",
    "    return x_padded, y_tensor\n",
    "\n",
    "# === Load and process each round ===\n",
    "x_first, y_first = process_round_data('data_for_first_round.npy', max_len=7)\n",
    "x_second, y_second = process_round_data('data_for_second_round.npy', max_len=7)\n",
    "x_third, y_third = process_round_data('data_for_third_round.npy', max_len=7)\n",
    "\n",
    "# === Concatenate all rounds ===\n",
    "x_all = torch.cat([x_first, x_second, x_third], dim=0)\n",
    "y_all = torch.cat([y_first, y_second, y_third], dim=0)\n",
    "\n",
    "# === Final dataset and dataloader ===\n",
    "dataset_all = TensorDataset(x_all, y_all)\n",
    "dataloader_all = DataLoader(dataset_all, batch_size=32, shuffle=True)\n",
    "\n",
    "# === Inspect sizes ===\n",
    "print(\"First round input shape:\", x_first.shape)\n",
    "print(\"First round label shape:\", y_first.shape)\n",
    "\n",
    "print(\"Second round input shape:\", x_second.shape)\n",
    "print(\"Second round label shape:\", y_second.shape)\n",
    "\n",
    "print(\"Third round input shape:\", x_third.shape)\n",
    "print(\"Third round label shape:\", y_third.shape)\n",
    "\n",
    "print(\"Combined input shape:\", x_all.shape)\n",
    "print(\"Combined label shape:\", y_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bff8ed",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "793584d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingNetLinear(nn.Module):\n",
    "    def __init__(self, num_cards=7, embed_dim=16):\n",
    "        super(EmbeddingNetLinear, self).__init__()\n",
    "        self.num_cards = num_cards\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(53, embed_dim, padding_idx=0)\n",
    "\n",
    "        self.fc1 = nn.Linear(num_cards * embed_dim, 64)  # Increased capacity\n",
    "        self.fc2 = nn.Linear(64, 32)                     # New layer\n",
    "        #self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)                       # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)  # Shape: [batch_size, num_cards, embed_dim]\n",
    "        flat = embedded.view(x.size(0), self.num_cards * self.embed_dim)\n",
    "        out = F.relu(self.fc1(flat))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        #out = F.relu(self.fc3(out))\n",
    "        return torch.sigmoid(self.fc4(out)).squeeze(1)\n",
    "    \n",
    "\n",
    "class EmbeddingNetConv1D(nn.Module):\n",
    "    def __init__(self, num_cards=7, embed_dim=16):\n",
    "        super(EmbeddingNetConv1D, self).__init__()\n",
    "        self.num_cards = num_cards\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(53, embed_dim, padding_idx=0)\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=embed_dim, out_channels=16, kernel_size=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3)\n",
    "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=4)\n",
    "\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)  # Reduces to [batch, 64, 1]\n",
    "\n",
    "        self.fc = nn.Linear(64, 1)  # Final output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)           # [batch, 7, embed_dim]\n",
    "        x = x.transpose(1, 2)           # [batch, embed_dim, 7]\n",
    "        x = F.relu(self.conv1(x))       # [batch, 32, 6]\n",
    "        x = F.relu(self.conv2(x))       # [batch, 64, 4]\n",
    "        x = F.relu(self.conv3(x))       # [batch, 64, 1]\n",
    "        x = self.pool(x).squeeze(-1)    # [batch, 64]\n",
    "        return torch.sigmoid(self.fc(x)).squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2cfbe9",
   "metadata": {},
   "source": [
    "## TRAIN FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efef154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, epochs=10, lr=0.001):\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()  # Because we're using sigmoid in the model\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for x_batch, y_batch in dataloader:\n",
    "            x_batch = x_batch\n",
    "            y_batch = y_batch\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(x_batch)\n",
    "\n",
    "            loss = criterion(preds, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            predicted = (preds > 0.5).float()\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "\n",
    "        acc = correct / total\n",
    "        print(f\"Epoch {epoch}/{epochs} | Loss: {total_loss:.4f} | Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5320ab64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Loss: 16962.4100 | Accuracy: 0.6268\n",
      "Epoch 2/100 | Loss: 16732.2004 | Accuracy: 0.6369\n",
      "Epoch 3/100 | Loss: 16624.9999 | Accuracy: 0.6374\n",
      "Epoch 4/100 | Loss: 16526.6715 | Accuracy: 0.6406\n",
      "Epoch 5/100 | Loss: 16436.4240 | Accuracy: 0.6456\n",
      "Epoch 6/100 | Loss: 16350.7676 | Accuracy: 0.6506\n",
      "Epoch 7/100 | Loss: 16266.2956 | Accuracy: 0.6549\n",
      "Epoch 8/100 | Loss: 16179.7527 | Accuracy: 0.6587\n",
      "Epoch 9/100 | Loss: 16092.0559 | Accuracy: 0.6619\n",
      "Epoch 10/100 | Loss: 16005.4049 | Accuracy: 0.6648\n",
      "Epoch 11/100 | Loss: 15922.2960 | Accuracy: 0.6674\n",
      "Epoch 12/100 | Loss: 15844.8415 | Accuracy: 0.6696\n",
      "Epoch 13/100 | Loss: 15772.6453 | Accuracy: 0.6718\n",
      "Epoch 14/100 | Loss: 15705.0260 | Accuracy: 0.6737\n",
      "Epoch 15/100 | Loss: 15640.9381 | Accuracy: 0.6756\n",
      "Epoch 16/100 | Loss: 15578.8517 | Accuracy: 0.6775\n",
      "Epoch 17/100 | Loss: 15519.0133 | Accuracy: 0.6794\n",
      "Epoch 18/100 | Loss: 15459.6826 | Accuracy: 0.6813\n",
      "Epoch 19/100 | Loss: 15402.2772 | Accuracy: 0.6834\n",
      "Epoch 20/100 | Loss: 15346.2759 | Accuracy: 0.6856\n",
      "Epoch 21/100 | Loss: 15291.8435 | Accuracy: 0.6876\n",
      "Epoch 22/100 | Loss: 15238.9285 | Accuracy: 0.6894\n",
      "Epoch 23/100 | Loss: 15187.9978 | Accuracy: 0.6914\n",
      "Epoch 24/100 | Loss: 15138.8026 | Accuracy: 0.6932\n",
      "Epoch 25/100 | Loss: 15091.0454 | Accuracy: 0.6949\n",
      "Epoch 26/100 | Loss: 15044.2999 | Accuracy: 0.6966\n",
      "Epoch 27/100 | Loss: 14998.9315 | Accuracy: 0.6982\n",
      "Epoch 28/100 | Loss: 14953.9372 | Accuracy: 0.6997\n",
      "Epoch 29/100 | Loss: 14909.6642 | Accuracy: 0.7014\n",
      "Epoch 30/100 | Loss: 14865.1070 | Accuracy: 0.7031\n",
      "Epoch 31/100 | Loss: 14820.7838 | Accuracy: 0.7046\n",
      "Epoch 32/100 | Loss: 14775.3517 | Accuracy: 0.7063\n",
      "Epoch 33/100 | Loss: 14730.1505 | Accuracy: 0.7079\n",
      "Epoch 34/100 | Loss: 14682.5894 | Accuracy: 0.7097\n",
      "Epoch 35/100 | Loss: 14634.3917 | Accuracy: 0.7113\n",
      "Epoch 36/100 | Loss: 14583.4896 | Accuracy: 0.7131\n",
      "Epoch 37/100 | Loss: 14531.2240 | Accuracy: 0.7148\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#convModel = EmbeddingNetConv1D(7, 16) \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#train_model(convModel, dataloader_all, 100, 0.0001)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m## simple linear 85%\u001b[39;00m\n\u001b[0;32m      5\u001b[0m linearModel \u001b[38;5;241m=\u001b[39m EmbeddingNetLinear(\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinearModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.00001\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 16\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloader, epochs, lr)\u001b[0m\n\u001b[0;32m     13\u001b[0m x_batch \u001b[38;5;241m=\u001b[39m x_batch\n\u001b[0;32m     14\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m y_batch\n\u001b[1;32m---> 16\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m preds \u001b[38;5;241m=\u001b[39m model(x_batch)\n\u001b[0;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(preds, y_batch)\n",
      "File \u001b[1;32mc:\\Users\\neomi\\anaconda3\\envs\\NSU25\\lib\\site-packages\\torch\\_compile.py:32\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[0;32m     30\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m disable_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\neomi\\anaconda3\\envs\\NSU25\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    741\u001b[0m prior_skip_guard_eval_unsafe \u001b[38;5;241m=\u001b[39m set_skip_guard_eval_unsafe(\n\u001b[0;32m    742\u001b[0m     _is_skip_guard_eval_unsafe_stance()\n\u001b[0;32m    743\u001b[0m )\n\u001b[0;32m    744\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    747\u001b[0m     _maybe_set_eval_frame(prior)\n",
      "File \u001b[1;32mc:\\Users\\neomi\\anaconda3\\envs\\NSU25\\lib\\site-packages\\torch\\optim\\optimizer.py:970\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[1;34m(self, set_to_none)\u001b[0m\n\u001b[0;32m    967\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    968\u001b[0m     per_device_and_dtype_grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_zero_grad_profile_name):\n\u001b[0;32m    971\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[0;32m    972\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\neomi\\anaconda3\\envs\\NSU25\\lib\\site-packages\\torch\\autograd\\profiler.py:752\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 752\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_function_enter_new\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\n\u001b[0;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\neomi\\anaconda3\\envs\\NSU25\\lib\\site-packages\\torch\\_ops.py:1123\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[1;32m-> 1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(kwargs \u001b[38;5;129;01mor\u001b[39;00m {}))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#convModel = EmbeddingNetConv1D(7, 16) \n",
    "\n",
    "#train_model(convModel, dataloader_all, 100, 0.0001)\n",
    "## simple linear 85%\n",
    "linearModel = EmbeddingNetLinear(7, 16)\n",
    "\n",
    "train_model(linearModel, dataloader_all, 100, 0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc45635",
   "metadata": {},
   "source": [
    "## TESTING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d6e6483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# define card set\n",
    "suits = ['Hearts', 'Diamonds', 'Clubs', 'Spades']\n",
    "ranks = ['2', '3', '4', '5', '6', '7', '8', '9', '10', 'J', 'Q', 'K', 'A']\n",
    "rank_values = {rank: i for i, rank in enumerate(ranks, start=2)}\n",
    "\n",
    "deck = [{'rank': rank, 'suit': suit} for suit in suits for rank in ranks]\n",
    "\n",
    "combinations = [\"High Card\", \"One Pair\", \"Two Pair\", \"Three of a Kind\", \"Four of a Kind\", \n",
    "                \"Full House\", \"Straight\", \"Flush\", \"Straight Flush\", \"Royal Flush\"]\n",
    "combinations_values = {combination: i for i, combination in enumerate(combinations, start=1)}\n",
    "# set ordered winning combinations\n",
    "winning_hands = [\"High Card\", \"One Pair\", \"Two Pair\", \"Three of a Kind\", \"Straight\", \"Flush\", \n",
    "                \"Full House\", \"Four of a Kind\", \"Straight Flush\", \"Royal Flush\"]\n",
    "\n",
    "winning_hand_ranks = {hand: i for i, hand in enumerate(winning_hands)}\n",
    "#enumerate the deck\n",
    "enumerated_deck = dict(enumerate(deck, start=1))\n",
    "num_deck = list(range(1, 53))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f170a25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_input_based_on_round(cards, round):\n",
    "    if round == 0:\n",
    "        input_cards = cards[:2]\n",
    "    elif round == 1:\n",
    "        input_cards = cards[:5]\n",
    "    else:\n",
    "        input_cards = cards[:7]\n",
    "    \n",
    "    # Convert to tensor\n",
    "    input_tensor = torch.tensor(input_cards, dtype=torch.long)\n",
    "\n",
    "    # Pad with zeros on the right if needed\n",
    "    if len(input_tensor) < 7:\n",
    "        pad_size = 7 - len(input_tensor)\n",
    "        input_tensor = F.pad(input_tensor, (0, pad_size), value=0)\n",
    "    else:\n",
    "        input_tensor = input_tensor[:7]  # Truncate just in case\n",
    "\n",
    "    return input_tensor.unsqueeze(0)  # shape: (max_len,)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "288dca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultimate\n",
    "def test_model_with_games(model, num_games = 100):\n",
    "    model.eval()\n",
    "    budget = 0\n",
    "    allBet = 0\n",
    "    folds = 0\n",
    "    flops = 0\n",
    "    rivers = 0\n",
    "    preflops = 0\n",
    "\n",
    "    for i in range(num_games): \n",
    "        # generate game (9 cards, played, river, dealer)\n",
    "        cards = random.sample(num_deck, 9)\n",
    "        winnings = 0\n",
    "\n",
    "        # check what round we are in\n",
    "        round = 0\n",
    "        round_when_bet = None\n",
    "        # play  game until it ends\n",
    "        while True:\n",
    "            model_input = get_model_input_based_on_round(cards, round)\n",
    "            \n",
    "            # Forward pass to get prediction (probability of betting 1)\n",
    "            with torch.no_grad():\n",
    "                pred = model(model_input)  # shape: [1, 1]\n",
    "\n",
    "            pred_prob = pred.item()  # get scalar probability\n",
    "\n",
    "            # if prediction > 0.5 => bet, else don't bet\n",
    "            if pred_prob > 0.5 and round_when_bet is None:\n",
    "                round_when_bet = round\n",
    "                break\n",
    "\n",
    "            round += 1\n",
    "\n",
    "            if round == 3:\n",
    "                break\n",
    "\n",
    "        # calculate winnings\n",
    "        player_hand = [enumerated_deck[card] for card in cards[0:7]]\n",
    "        dealer_hand = [enumerated_deck[card] for card in cards[2:]]\n",
    "\n",
    "        player_combination = ultimate.get_best_hand(player_hand)\n",
    "        dealer_combination = ultimate.get_best_hand(dealer_hand)\n",
    "\n",
    "        player_rank = winning_hand_ranks[player_combination]\n",
    "        dealer_rank = winning_hand_ranks[dealer_combination]\n",
    "\n",
    "        victor = 0 # 0 = dealer, 1 = player\n",
    "        \n",
    "        if player_rank > dealer_rank:\n",
    "            victor = 1\n",
    "        elif player_rank == dealer_rank:\n",
    "            result = ultimate.decider(player_combination, player_hand, \n",
    "                                    dealer_combination, dealer_hand)\n",
    "            if result == \"player\":\n",
    "                victor = 1\n",
    "            elif result == \"dealer\":\t\n",
    "                victor = 0\n",
    "            else:\n",
    "                victor = 2\t# need to decide about this\n",
    "                winnings = 0\n",
    "        else:\n",
    "            victor = 0\n",
    "\n",
    "        # check if ante is valid\n",
    "        dealer_has_something = ultimate.dealer_has_pair_or_better(dealer_hand[:2], dealer_hand[2:])\n",
    "        blind_won = ultimate.has_blind(1, player_combination) - 1 #how much blind got us\n",
    "\n",
    "        # calculate rewards for first and second rounds (in third victory is already bet, defeat is fold)\n",
    "        if round_when_bet == 0:\n",
    "            if victor == 1:\n",
    "                winnings =  4 + blind_won + (1 if dealer_has_something else 0)\n",
    "            elif victor == 0:\n",
    "                winnings =  -6\n",
    "            allBet += 6\n",
    "            preflops += 1\n",
    "        elif round_when_bet == 1:\n",
    "            if victor == 1:\n",
    "                winnings =  2 + blind_won + (1 if dealer_has_something else 0)\n",
    "            elif victor == 0:\n",
    "                winnings =  -4\n",
    "            allBet += 4\n",
    "            flops += 1\n",
    "        elif round_when_bet == 2:\n",
    "            if victor == 1:\n",
    "                winnings =  1 + blind_won + (1 if dealer_has_something else 0)\n",
    "            elif victor == 0:\n",
    "                winnings =  -3\n",
    "            allBet += 3\n",
    "            rivers += 1\n",
    "        elif round_when_bet == None:\n",
    "            winnings = -2\n",
    "            allBet += 2\n",
    "            folds += 1\n",
    "        \n",
    " \n",
    "        budget += winnings\n",
    "        #print(\"Winnings: \", winnings)\n",
    "    \n",
    "    print(\"Budget is: \", budget)\n",
    "    print(\"Betted: \", allBet)\n",
    "    print(\"PreFlops: \", preflops)\n",
    "    print(\"Flops:\", flops)\n",
    "    print(\"Rivers:\", rivers)\n",
    "    print(\"Folds: \", folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f0e09a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget is:  -4951.0\n",
      "Betted:  36456\n",
      "PreFlops:  3144\n",
      "Flops: 1604\n",
      "Rivers: 672\n",
      "Folds:  4580\n"
     ]
    }
   ],
   "source": [
    "test_model_with_games(embeddingModel, 10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NSU25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
